{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv4 학습하고 Edge TPU complie하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing: 100%|██████████| 4448/4448 [00:00<00:00, 5461.86it/s] \n",
      "Saving: 100%|██████████| 3609/3609 [00:00<00:00, 192248.26it/s]\n"
     ]
    }
   ],
   "source": [
    "## data convert : json to txt\n",
    "## 데이터 세트를 학습에 적합한 txt로 변환 \n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "INSTANCES_PATH = \"/home/piai/yolov4-tiny/data_anno/_annotations.coco.json\"\n",
    "NAMES_PATH = \"/home/piai/yolov4-tiny/data_anno/custom.names\"\n",
    "OUTPUT_FILE_PATH = \"/home/piai/yolov4-tiny/data_anno/custom_train.txt\"\n",
    "\n",
    "coco = json.load(open(INSTANCES_PATH))\n",
    "images = coco[\"images\"]\n",
    "annotations = coco[\"annotations\"]\n",
    "categories = coco[\"categories\"]\n",
    "replaced_name = {\n",
    "    \"couch\": \"sofa\",\n",
    "    \"airplane\": \"aeroplane\",\n",
    "    \"tv\": \"tvmonitor\",\n",
    "    \"motorcycle\": \"motorbike\",\n",
    "}\n",
    "\n",
    "class_to_id = {}\n",
    "id_to_class = {}\n",
    "with open(NAMES_PATH, \"r\") as fd:\n",
    "    index = 0\n",
    "    for class_name in fd:\n",
    "        class_name = class_name.strip()\n",
    "        if len(class_name) != 0:\n",
    "            id_to_class[index] = class_name\n",
    "            class_to_id[class_name] = index\n",
    "            index += 1\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "for annotation in tqdm(annotations, desc=\"Parsing\"):\n",
    "    image_id = annotation[\"image_id\"]\n",
    "    category_id = annotation[\"category_id\"]\n",
    "\n",
    "    # Find image\n",
    "    file_name = None\n",
    "    image_height = 0\n",
    "    image_width = 0\n",
    "    for image in images:\n",
    "        if image[\"id\"] == image_id:\n",
    "            file_name = image[\"file_name\"]\n",
    "            image_height = image[\"height\"]\n",
    "            image_width = image[\"width\"]\n",
    "            break\n",
    "\n",
    "    if file_name is None:\n",
    "        continue\n",
    "\n",
    "    # Find class id\n",
    "    class_id = None\n",
    "    for category in categories:\n",
    "        if category[\"id\"] == category_id:\n",
    "            category_name = category[\"name\"]\n",
    "            if category_name in replaced_name:\n",
    "                category_name = replaced_name[category_name]\n",
    "\n",
    "            class_id = class_to_id.get(category_name)\n",
    "            break\n",
    "\n",
    "    if class_id is None:\n",
    "        continue\n",
    "\n",
    "    # Calculate x,y,w,h\n",
    "    x_center = annotation[\"bbox\"][0] + annotation[\"bbox\"][2] / 2\n",
    "    x_center /= image_width\n",
    "    y_center = annotation[\"bbox\"][1] + annotation[\"bbox\"][3] / 2\n",
    "    y_center /= image_height\n",
    "    width = annotation[\"bbox\"][2] / image_width\n",
    "    height = annotation[\"bbox\"][3] / image_height\n",
    "\n",
    "    if dataset.get(image_id):\n",
    "        dataset[image_id][1].append(\n",
    "            [class_id, x_center, y_center, width, height]\n",
    "        )\n",
    "    else:\n",
    "        dataset[image_id] = [\n",
    "            file_name,\n",
    "            [[class_id, x_center, y_center, width, height]],\n",
    "        ]\n",
    "\n",
    "dataset = OrderedDict(sorted(dataset.items()))\n",
    "\n",
    "with open(OUTPUT_FILE_PATH, \"w\") as fd:\n",
    "    for image_id, bboxes in tqdm(dataset.items(), desc=\"Saving\"):\n",
    "        data = bboxes[0]\n",
    "        for bbox in bboxes[1]:\n",
    "            data += \" \"\n",
    "            data += \"{:d},\".format(bbox[0])\n",
    "            data += \"{:8.6f},\".format(bbox[1])\n",
    "            data += \"{:8.6f},\".format(bbox[2])\n",
    "            data += \"{:8.6f},\".format(bbox[3])\n",
    "            data += \"{:8.6f}\".format(bbox[4])\n",
    "\n",
    "        data += \"\\n\"\n",
    "        fd.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##training \n",
    "## weight 파일 저장하는곳 \n",
    "## --> https://wiki.loliot.net/docs/lang/python/libraries/yolov4/python-yolov4-about/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call tf.config.experimental.set_memory_growth(GPU0, True)\n"
     ]
    }
   ],
   "source": [
    "from yolov4.tf import YOLOv4, YOLODataset, save_as_tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train (GPU 켜고 시작하기)\n",
    "\n",
    "- 데이터 초기에 생성하고 모델만 하이퍼 파라미터 고쳐가면서 테스트 할때는 여기부터 돌리면 됨\n",
    "\n",
    "- 커널이 자꾸 죽는다면 뭔가 이상한것 (재부팅하고 학습하더라도 성능이 좋지 않으니 왜 오류 나는지 원인 찾아서 고치고 학습하기)\n",
    "- 이번 프로젝트에서는 cfg파일과 weight가 안맞아서 생긴 문제였음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14585165190811375393,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 7601236224\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 848542186437093552\n",
       " physical_device_desc: \"device: 0, name: GeForce RTX 2080, pci bus id: 0000:17:00.0, compute capability: 7.5\",\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 7223296672\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 201580105044240433\n",
       " physical_device_desc: \"device: 1, name: GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[0:1], 'GPU')\n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train\n",
    "## epoch = 240000 / lr = 0.0003 / burn_in = 2000\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from yolov4.tf import YOLOv4, YOLODataset, SaveWeightsCallback\n",
    "\n",
    "yolo = YOLOv4()\n",
    "yolo.config.parse_names(\"data/custom.names\")\n",
    "yolo.config.parse_cfg(\"config/yolov4-tiny-relu.cfg\")\n",
    "\n",
    "yolo.make_model()\n",
    "yolo.load_weights(\n",
    "    \"yolov4-tiny.conv.29\",\n",
    "    weights_type=\"yolo\",\n",
    ")\n",
    "yolo.summary(summary_type=\"yolo\")\n",
    "\n",
    "for i in range(29):\n",
    "    yolo.model.get_layer(index=i).trainable = False\n",
    "    \n",
    "yolo.summary()\n",
    "\n",
    "train_dataset = YOLODataset(\n",
    "    config=yolo.config,\n",
    "    dataset_list = \"data/custom_train_true.txt\",\n",
    "    image_path_prefix=\"data/train\",\n",
    "    training=True,\n",
    ")\n",
    "\n",
    "'''\n",
    "val_dataset = YOLODataset(\n",
    "    config=yolo.config,\n",
    "    dataset_list=\"/home/piai/yolov4-tiny/data_anno/custom_validation.txt\",\n",
    "    image_path_prefix=\"/home/piai/yolov4-tiny/data_anno/train\",\n",
    "    training=False,\n",
    ")\n",
    "'''\n",
    "\n",
    "yolo.compile()\n",
    "\n",
    "_callbacks = [\n",
    "    SaveWeightsCallback(\n",
    "        yolo=yolo,\n",
    "        #dir_path=\"/home/piai/tensorflow-yolov4-master/trained\",\n",
    "        weights_type=\"yolo\",\n",
    "        step_per_save=5000,\n",
    "    ),\n",
    "]\n",
    "\n",
    "yolo.fit(\n",
    "    train_dataset,\n",
    "    callbacks=_callbacks,\n",
    "    #validation_data=val_dataset,\n",
    "    verbose=3,  # 3: print step info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "학습결과 \n",
    "Avg IoU - 현재의 subdivision에서 이미지 평균 IoU\n",
    "class - 1에 가까울수록 학습 잘되고있는것\n",
    "No Obj - 0이 아닌 작은 값이어야 함 \n",
    ".5R - recall/count \n",
    ".75R - 0.0000\n",
    "count -현재 subdivision 이미지들에서 positive sample을 포함한 이미지의 수\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weights 파일 변환하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyjw7fhz_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyjw7fhz_/assets\n",
      "WARNING:absl:Please consider switching to the new converter by setting experimental_new_converter=True. The old converter (TOCO) is deprecated.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    ".weights --> .tflite 변환\n",
    "모델 생성시 사용한 cfg 파일의 conv 옵션과 변환하려는 모델 cfg 파일의 conv 옵션을 맞춰줘야 함 (filter 개수) \n",
    "\n",
    "'''\n",
    "\n",
    "from yolov4.tf import YOLOv4, YOLODataset, save_as_tflite\n",
    "\n",
    "\n",
    "yolo = YOLOv4()\n",
    "yolo.config.parse_names(\"data/custom.names\")\n",
    "yolo.config.parse_cfg(\"config/yolov4-tiny-relu-tpu.cfg\")\n",
    "\n",
    "yolo.make_model()\n",
    "yolo.load_weights(\n",
    "    \"0415trained-weights/yolov4-tiny-relu-final.weights\", weights_type=\"yolo\"\n",
    ")\n",
    "\n",
    "dataset = YOLODataset(\n",
    "    config=yolo.config,\n",
    "    dataset_list = \"data/custom_train_true.txt\",\n",
    "    image_path_prefix=\"data/train\",\n",
    "    training=False\n",
    ")\n",
    "\n",
    "save_as_tflite(\n",
    "    model=yolo.model,\n",
    "    tflite_path=\"0415_yolov4-tiny-relu-int8.tflite\",\n",
    "    quantization=\"full_int8\",\n",
    "    dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge TPU complier 사용하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge TPU Compiler version 15.0.340273435\n",
      "\n",
      "Model compiled successfully in 799 ms.\n",
      "\n",
      "Input model: 0415_yolov4-tiny-relu-int8.tflite\n",
      "Input size: 5.73MiB\n",
      "Output model: 0415_yolov4-tiny-relu-int8_edgetpu.tflite\n",
      "Output size: 5.76MiB\n",
      "On-chip memory used for caching model parameters: 4.82MiB\n",
      "On-chip memory remaining for caching model parameters: 1.88MiB\n",
      "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
      "Number of Edge TPU subgraphs: 1\n",
      "Total number of operations: 51\n",
      "Operation log: 0415_yolov4-tiny-relu-int8_edgetpu.log\n",
      "\n",
      "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
      "Number of operations that will run on Edge TPU: 41\n",
      "Number of operations that will run on CPU: 10\n",
      "See the operation log file for individual operation details.\n"
     ]
    }
   ],
   "source": [
    "! edgetpu_compiler  '0415_yolov4-tiny-relu-int8.tflite'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
